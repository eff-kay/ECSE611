From f8926e5f7215e5cf980bc429f3170ea6cd7eae47 Mon Sep 17 00:00:00 2001
From: Pankaj <pankaj.kr@huawei.com>
Date: Tue, 24 Jul 2018 19:40:36 +0530
Subject: [PATCH] HBASE-9888 HBase replicates edits written before the
 replication peer is created

---
 .../hadoop/hbase/replication/ReplicationPeer.java  |   5 +
 .../hbase/replication/ReplicationPeerZKImpl.java   |  21 ++++
 .../hbase/replication/ReplicationPeersZKImpl.java  |   8 ++
 .../java/org/apache/hadoop/hbase/HConstants.java   |   4 +
 .../replication/WALKeyWriteTimeBasedFilter.java    |  46 +++++++++
 .../regionserver/ReplicationSource.java            |  22 ++++
 .../hbase/replication/TestReplicationEndpoint.java |   1 +
 .../TestWALKeyWriteTimeBasedFilter.java            | 114 +++++++++++++++++++++
 8 files changed, 221 insertions(+)
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/replication/WALKeyWriteTimeBasedFilter.java
 create mode 100644 hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestWALKeyWriteTimeBasedFilter.java

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java
index a0e758f..ec294b1 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java
@@ -87,4 +87,9 @@ public interface ReplicationPeer {
    * @param listener Listener for config changes, usually a replication endpoint
    */
   void removeListenerOfPeerConfig(ReplicationPeerConfigListener listener);
+
+  /**
+   * @return create time for a replication peer
+   */
+  long getCreationTime();
 }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java
index 57b118d..c6aafdb 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java
@@ -42,6 +42,7 @@ import org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker;
 import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
 import org.apache.zookeeper.KeeperException;
 import org.apache.zookeeper.KeeperException.NodeExistsException;
+import org.apache.zookeeper.data.Stat;
 
 @InterfaceAudience.Private
 public class ReplicationPeerZKImpl extends ReplicationStateZKBase implements ReplicationPeer,
@@ -57,6 +58,9 @@ public class ReplicationPeerZKImpl extends ReplicationStateZKBase implements Rep
   private PeerStateTracker peerStateTracker;
   private PeerConfigTracker peerConfigTracker;
 
+  // initialize the node creation time to be used for comparison with WALKey writeTime
+  private long createTime = Long.MIN_VALUE;
+
   /**
    * Constructor that takes all the objects required to communicate with the specified peer, except
    * for the region server addresses.
@@ -207,6 +211,23 @@ public class ReplicationPeerZKImpl extends ReplicationStateZKBase implements Rep
     // TODO: stop zkw?
   }
 
+  @Override
+  public long getCreationTime() {
+    return this.createTime;
+  }
+
+  /**
+   * below method for internal usage only initialize this peer's create time
+   * @param zookeeper
+   * @param peerNode
+   * @throws KeeperException
+   */
+  void initCreateTime(final ZooKeeperWatcher zookeeper, String peerNode) throws KeeperException {
+    final Stat stat = new Stat();
+    ZKUtil.getDataNoWatch(zookeeper, peerNode, stat);
+    this.createTime = stat.getCtime();
+  }
+
   /**
    * Parse the raw data from ZK to get a peer's state
    * @param bytes raw ZK data
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java
index 6fefb36..45abfb3 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java
@@ -509,6 +509,14 @@ public class ReplicationPeersZKImpl extends ReplicationStateZKBase implements Re
           peerId, e);
     }
 
+    // init peer create time
+    try {
+      peer.initCreateTime(this.zookeeper, getPeerNode(peerId));
+    } catch (KeeperException e) {
+      throw new ReplicationException("Error initializing the peer create time for peerId=" + peerId,
+          e);
+    }
+
     try {
       peer.startPeerConfigTracker(this.zookeeper, this.getPeerNode(peerId));
     }
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
index 3d1115b..c1f1fe9 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
@@ -1223,6 +1223,10 @@ public final class HConstants {
   /** Maximum number of threads used by the replication source for shipping edits to the sinks */
   public static final int REPLICATION_SOURCE_MAXTHREADS_DEFAULT = 10;
 
+  /** Config parameter to enable/disable wal key write time filter */
+  public static final String HBASE_REPLICATION_WAL_KEY_WRITE_TIME_FILTER_ENABLED =
+      "hbase.replication.walKeyWriteTime.filter.enabled";
+
   /** Config for pluggable consensus provider */
   public static final String HBASE_COORDINATED_STATE_MANAGER_CLASS =
     "hbase.coordinated.state.manager.class";
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/WALKeyWriteTimeBasedFilter.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/WALKeyWriteTimeBasedFilter.java
new file mode 100644
index 0000000..bb2a1ec
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/WALKeyWriteTimeBasedFilter.java
@@ -0,0 +1,46 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.replication;
+
+import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.wal.WAL.Entry;
+
+/**
+ * This WALKEy writeTime based filter can be used to make sure replication source replicates only
+ * those WAL entries for which WalKey writeTime is after the creation time of replication source
+ */
+@InterfaceAudience.Private
+public class WALKeyWriteTimeBasedFilter implements WALEntryFilter {
+  private long baseWriteTime = Long.MIN_VALUE;
+
+  public WALKeyWriteTimeBasedFilter(long currentTime) {
+    this.baseWriteTime = currentTime;
+  }
+
+  @Override
+  public Entry filter(Entry entry) {
+    final long writeTime = entry.getKey().getWriteTime();
+    // when time is equal then allow replication?
+    if (writeTime < baseWriteTime) {
+      return null;
+    }
+    return entry;
+  }
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
index 2396655..c5cb230 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
@@ -63,6 +63,7 @@ import org.apache.hadoop.hbase.replication.ReplicationQueueInfo;
 import org.apache.hadoop.hbase.replication.ReplicationQueues;
 import org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter;
 import org.apache.hadoop.hbase.replication.WALEntryFilter;
+import org.apache.hadoop.hbase.replication.WALKeyWriteTimeBasedFilter;
 import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.WALEntryBatch;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
@@ -292,6 +293,15 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     // get the WALEntryFilter from ReplicationEndpoint and add it to default filters
     ArrayList<WALEntryFilter> filters = Lists.newArrayList(
       (WALEntryFilter)new SystemTableWALEntryFilter());
+
+    // add filter based on WALKey timestamp so that we do not replicate anything that was
+    // added before this ReplicationSource is created
+    final WALEntryFilter walKeyWriteTimeBasedFilter = initWALKeyWriteTimeFilter();
+    if (walKeyWriteTimeBasedFilter != null) {
+      filters.add(walKeyWriteTimeBasedFilter);
+      LOG.info("WALKey writeTime based filter for replication is enabled.");
+    }
+
     WALEntryFilter filterFromEndpoint = this.replicationEndpoint.getWALEntryfilter();
     if (filterFromEndpoint != null) {
       filters.add(filterFromEndpoint);
@@ -501,6 +511,18 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     return peerBandwidth != 0 ? peerBandwidth : defaultBandwidth;
   }
 
+  /**
+   * Add filter based on WALKey timestamp
+   */
+  private WALEntryFilter initWALKeyWriteTimeFilter() {
+    if (this.conf.getBoolean(HConstants.HBASE_REPLICATION_WAL_KEY_WRITE_TIME_FILTER_ENABLED,
+      true)) {
+      return new WALKeyWriteTimeBasedFilter(
+          this.replicationPeers.getPeer(this.peerId).getCreationTime());
+    }
+    return null;
+  }
+
   // This thread reads entries from a queue and ships them.
   // Entries are placed onto the queue by ReplicationSourceWALReaderThread
   public class ReplicationSourceShipperThread extends Thread {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
index 3b984ab..5de2b3d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
@@ -69,6 +69,7 @@ public class TestReplicationEndpoint extends TestReplicationBase {
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
+    conf1.setBoolean("hbase.replication.walKeyWriteTime.filter.enabled", false);
     TestReplicationBase.setUpBeforeClass();
     admin.removePeer("2");
     numRegionServers = utility1.getHBaseCluster().getRegionServerThreads().size();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestWALKeyWriteTimeBasedFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestWALKeyWriteTimeBasedFilter.java
new file mode 100644
index 0000000..a7629f0
--- /dev/null
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestWALKeyWriteTimeBasedFilter.java
@@ -0,0 +1,114 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.replication;
+
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.Connection;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.testclassification.MediumTests;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category(MediumTests.class)
+public class TestWALKeyWriteTimeBasedFilter extends TestReplicationBase {
+  private static final Log LOG = LogFactory.getLog(TestWALKeyWriteTimeBasedFilter.class);
+
+  @Test
+  public void testOldTableDataReplicationUponPeerReAddition()
+      throws InterruptedException, IOException, ReplicationException {
+    // Put records in source table
+    Put put = new Put(row);
+    put.addColumn(famName, "c1".getBytes(), "v1".getBytes());
+    htable1.put(put);
+    put = new Put("row2".getBytes());
+    put.addColumn(famName, "c1".getBytes(), "v2".getBytes());
+    htable1.put(put);
+
+    // wait for above put to replicate in peer cluster
+    for (int i = 0; i < NB_RETRIES; i++) {
+      if (i == NB_RETRIES - 1) {
+        fail("Waited too much time for put replication");
+      }
+      int count = utility2.countRows(htable2);
+      if (count < 2) {
+        LOG.debug("Rows still not available in peer table");
+        Thread.sleep(500);
+      } else {
+        assertTrue("data replicated to peer for 2 rows", count == 2);
+        break;
+      }
+    }
+
+    // Remove peer
+    admin.removePeer(PEER_ID);
+
+    // Truncate the table from source cluster
+    try (Connection conn1 = ConnectionFactory.createConnection(conf1);
+        Admin admin1 = conn1.getAdmin()) {
+      admin1.disableTable(tableName);
+      admin1.truncateTable(tableName, false);
+    }
+    assertTrue("table data should be deleted from source", utility1.countRows(htable1) == 0);
+
+    // Truncate the table from peer cluster
+    try (Connection conn2 = ConnectionFactory.createConnection(conf2);
+        Admin admin2 = conn2.getAdmin()) {
+      admin2.disableTable(tableName);
+      admin2.truncateTable(tableName, false);
+    }
+    assertTrue("table data should be deleted from peer", utility2.countRows(htable2) == 0);
+
+    // add peer again
+    admin.addPeer(PEER_ID, new ReplicationPeerConfig().setClusterKey(utility2.getClusterKey()),
+      null);
+
+    // add a new row to source cluster table
+    put = new Put("row3".getBytes());
+    put.addColumn(famName, "c1".getBytes(), "v33".getBytes());
+    htable1.put(put);
+    assertTrue("table data should be deleted from source", utility1.countRows(htable1) == 1);
+
+    // Wait for replication so that actual row count should be 1
+    for (int i = 0; i < NB_RETRIES; i++) {
+      if (i == NB_RETRIES - 1) {
+        fail("Waited too much time for put replication");
+      }
+      int count = utility2.countRows(htable2);
+      if (count < 1) {
+        System.out.println("Rows still not available in peer table");
+        Thread.sleep(5000);
+      } else if (count > 1) {
+        fail("peer table row count is " + count + ", it should not be > 1");
+        break;
+      } else {
+        assertTrue("data replicated to peer for 2 rows", count == 1);
+        break;
+      }
+    }
+  }
+}
\ No newline at end of file
-- 
2.7.4

